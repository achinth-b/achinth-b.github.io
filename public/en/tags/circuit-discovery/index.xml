<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Circuit-Discovery on achinth</title>
    <link>https://achinth-b.github.io/en/tags/circuit-discovery/</link>
    <description>Recent content in Circuit-Discovery on achinth</description>
    <generator>Hugo</generator>
    <language>en-CA</language>
    <lastBuildDate>Tue, 10 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://achinth-b.github.io/en/tags/circuit-discovery/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[PART 1] circuit discovery: what the hell is it?</title>
      <link>https://achinth-b.github.io/en/posts/circuit-discovery-1/</link>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://achinth-b.github.io/en/posts/circuit-discovery-1/</guid>
      <description>&lt;p&gt;&lt;em&gt;This is part one of a series of posts about learning biased circuits in vision/language models. I want to publish a paper to ICML at the end of this.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Like most people, I don&amp;rsquo;t know anything about this entire sub-field.&#xA;It&amp;rsquo;s exhausting, humbling and most of all - exciting to learn something new about how we can understand generative models.&lt;/p&gt;&#xA;&lt;p&gt;Thanks to &lt;a href=&#34;https://www.perplexity.ai/&#34;&gt;perplexity&lt;/a&gt;, I get to learn what this subfield is. Let&amp;rsquo;s get started.&lt;/p&gt;&#xA;&lt;h2 class=&#34;heading&#34; id=&#34;what-is-circuit-discovery-and-how-did-we-get-here&#34;&gt;&#xA;  what is circuit discovery and how did we get here?&lt;span class=&#34;heading__anchor&#34;&gt; &lt;a href=&#34;#what-is-circuit-discovery-and-how-did-we-get-here&#34;&gt;#&lt;/a&gt;&lt;/span&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Circuit discovery is a technique from mechanistic interpretability which aims to identify and analyze the internals of generative models.&#xA;The abstraction tis technique interfaces with is on identifying &amp;lsquo;circuits&amp;rsquo; - or more precisely, pathways through which transformers process information.&lt;/p&gt;&#xA;&lt;h3 class=&#34;heading&#34; id=&#34;contextual-decomposition&#34;&gt;&#xA;  contextual decomposition&lt;span class=&#34;heading__anchor&#34;&gt; &lt;a href=&#34;#contextual-decomposition&#34;&gt;#&lt;/a&gt;&lt;/span&gt;&#xA;&lt;/h3&gt;&lt;p&gt;One method method of circuit discovery in transformers is &amp;lsquo;contextual decomposition (CD) for transformers&amp;rsquo;. This works by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;recursive computation: CD recursively computes the contributions of all nodes (eg. attention heads, neurons) in the model&amp;rsquo;s computational graph. This means that for each output, the method assesses how much each component controbutes to the output based on its interactions with other components.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;equations: this method uses a set of well-defined equations which isolate the contributions of one model feature from another. This allows for a clear understanding of how specific features affect the overall behaviour of the model.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;pruning: after the contributions have been calculated, CD applies a pruning step to removes node that insignificantly impact the output. THis step simplifies the discovered circuit and focuses on the most relevant components.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 class=&#34;heading&#34; id=&#34;advantages-and-disadvantages-of-contextual-decomposition&#34;&gt;&#xA;  advantages and disadvantages of contextual decomposition&lt;span class=&#34;heading__anchor&#34;&gt; &lt;a href=&#34;#advantages-and-disadvantages-of-contextual-decomposition&#34;&gt;#&lt;/a&gt;&lt;/span&gt;&#xA;&lt;/h4&gt;&lt;p&gt;Having been evaluated over several circuit evaluation tasks such as indiret object identification and greater-than comparisons, CD has a high degree of faithfulness to the original model&amp;rsquo;s behaviour, replicating its performance for fewer nodes than competing approaches. It also doesn&amp;rsquo;t require manual crafting of examples or additional training, making it applicable across various transformer architectures.&lt;/p&gt;&#xA;&lt;h3 class=&#34;heading&#34; id=&#34;sparse-autoencoders&#34;&gt;&#xA;  sparse autoencoders&lt;span class=&#34;heading__anchor&#34;&gt; &lt;a href=&#34;#sparse-autoencoders&#34;&gt;#&lt;/a&gt;&lt;/span&gt;&#xA;&lt;/h3&gt;&lt;p&gt;Sparse autoencoders (SAEs) are a specialized type of autoencoder which focuses on learning efficient represntations of data by enforcing sparsity in encoded representations. This works by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;compressing input data into a lower-dimensional representation and a decoder that reconstructs the original input from this representation - with the added benefit of enforcing a sparsity constraint in the latent space by adding it to the loss function (which I just was reminded - is L1 regularization.)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;breaking down neural networks into understandable components without requiring labelled examples. Since sparsity is enforced, most noisy variables are ignored as well as irrelevant information.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;</description>
    </item>
  </channel>
</rss>
